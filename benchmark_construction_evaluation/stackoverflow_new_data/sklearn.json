[{"votes": "326", "answers": [{"answer_content": "You can easily do this though,\ndf.apply(LabelEncoder().fit_transform)\n\nEDIT2:\nIn scikit-learn 0.20, the recommended way is\nOneHotEncoder().fit_transform(df)\n\nas the OneHotEncoder now supports string input.\nApplying OneHotEncoder only to certain columns is possible with the ColumnTransformer.\nEDIT:\nSince this original answer is over a year ago, and generated many upvotes (including a bounty), I should probably extend this further.\nFor inverse_transform and transform, you have to do a little bit of hack.\nfrom collections import defaultdict\nd = defaultdict(LabelEncoder)\n\nWith this, you now retain all columns LabelEncoder as dictionary.\n# Encoding the variable\nfit = df.apply(lambda x: d[x.name].fit_transform(x))\n\n# Inverse the encoded\nfit.apply(lambda x: d[x.name].inverse_transform(x))\n\n# Using the dictionary to label future data\ndf.apply(lambda x: d[x.name].transform(x))\n\nMOAR EDIT:\nUsing Neuraxle's FlattenForEach step, it's possible to do this as well to use the same LabelEncoder on all the flattened data at once:\nFlattenForEach(LabelEncoder(), then_unflatten=True).fit_transform(df)\n\nFor using separate LabelEncoders depending for your columns of data, or if only some of your columns of data needs to be label-encoded and not others, then using a ColumnTransformer is a solution that allows for more control on your column selection and your LabelEncoder instances.", "answer_comment": ["This is Amazing, but in this case how can we apply inverse transform ?", "But if I want to use this solution in a pipeline e.g. separate fit and transform (fit on train, and then use on test-set --> re-use the learnt dictionary) is this supported with df.apply(LabelEncoder().fit_transform)?", "How can this be made to work with LabelBinarizer instead and re-use the dictionary for a test set? I tried d = defaultdict(LabelBinarizer) and then fit = df.apply(lambda x: d[x.name].fit_transform(x)) but an exception is raised: Exception: Data must be 1-dimensional. I'm not sure how I expect the resulting DataFrame to look like... maybe each column should hold the binarized vectors.", "Nice solution. How to transform in certain column only?", "if i want to inverse the encode juste for one column, how do i do it ?"], "answer_score": "609", "answer_code_list": ["df.apply(LabelEncoder().fit_transform)\n", "OneHotEncoder().fit_transform(df)\n", "from collections import defaultdict\nd = defaultdict(LabelEncoder)\n", "# Encoding the variable\nfit = df.apply(lambda x: d[x.name].fit_transform(x))\n\n# Inverse the encoded\nfit.apply(lambda x: d[x.name].inverse_transform(x))\n\n# Using the dictionary to label future data\ndf.apply(lambda x: d[x.name].transform(x))\n", "FlattenForEach(LabelEncoder(), then_unflatten=True).fit_transform(df)\n"], "is_accepted": false}, {"answer_content": "As mentioned by larsmans, LabelEncoder() only takes a 1-d array as an argument. That said, it is quite easy to roll your own label encoder that operates on multiple columns of your choosing, and returns a transformed dataframe. My code here is based in part on Zac Stewart's excellent blog post found here.\nCreating a custom encoder involves simply creating a class that responds to the fit(), transform(), and fit_transform() methods. In your case, a good start might be something like this:\n\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.pipeline import Pipeline\n\n# Create some toy data in a Pandas dataframe\nfruit_data = pd.DataFrame({\n    'fruit':  ['apple','orange','pear','orange'],\n    'color':  ['red','orange','green','green'],\n    'weight': [5,6,3,4]\n})\n\nclass MultiColumnLabelEncoder:\n    def __init__(self,columns = None):\n        self.columns = columns # array of column names to encode\n\n    def fit(self,X,y=None):\n        return self # not relevant here\n\n    def transform(self,X):\n        '''\n        Transforms columns of X specified in self.columns using\n        LabelEncoder(). If no columns specified, transforms all\n        columns in X.\n        '''\n        output = X.copy()\n        if self.columns is not None:\n            for col in self.columns:\n                output[col] = LabelEncoder().fit_transform(output[col])\n        else:\n            for colname,col in output.iteritems():\n                output[colname] = LabelEncoder().fit_transform(col)\n        return output\n\n    def fit_transform(self,X,y=None):\n        return self.fit(X,y).transform(X)\n\nSuppose we want to encode our two categorical attributes (fruit and color), while leaving the numeric attribute weight alone. We could do this as follows:\n\nMultiColumnLabelEncoder(columns = ['fruit','color']).fit_transform(fruit_data)\n\nWhich transforms our fruit_data dataset from\n to \n\nPassing it a dataframe consisting entirely of categorical variables and omitting the columns parameter will result in every column being encoded (which I believe is what you were originally looking for):\n\nMultiColumnLabelEncoder().fit_transform(fruit_data.drop('weight',axis=1))\n\nThis transforms\n to\n.\nNote that it'll probably choke when it tries to encode attributes that are already numeric (add some code to handle this if you like).\nAnother nice feature about this is that we can use this custom transformer in a pipeline:\n\nencoding_pipeline = Pipeline([\n    ('encoding',MultiColumnLabelEncoder(columns=['fruit','color']))\n    # add more pipeline steps as needed\n])\nencoding_pipeline.fit_transform(fruit_data)", "answer_comment": ["Just realized the data implies that an orange is colored green. Oops. ;)", "this is a good way to transform data once, but what if i want to reuse this transform on a validation set. you would have to fit_transform again and issues could arise such as my new data set not having all the categories for all variables. eg., say the color green does not show up in my new data set. this will mess up the encoding.", "Agreed with @Ben. This doesn't actually mimic sklearn at all beyond the method names. If you tried to put this in a Pipeline, it wouldn't work", "To make sure the label encoding is consistent across both the train and test sets, you'll want to perform the encoding on your entire dataset (train + test). This can be done either before you split them into train and test, or you can combine them, perform the encoding, and split them back out again.", "How about going reverse ? decoding back to the original ?"], "answer_score": "131", "answer_code_list": ["import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.pipeline import Pipeline\n\n# Create some toy data in a Pandas dataframe\nfruit_data = pd.DataFrame({\n    'fruit':  ['apple','orange','pear','orange'],\n    'color':  ['red','orange','green','green'],\n    'weight': [5,6,3,4]\n})\n\nclass MultiColumnLabelEncoder:\n    def __init__(self,columns = None):\n        self.columns = columns # array of column names to encode\n\n    def fit(self,X,y=None):\n        return self # not relevant here\n\n    def transform(self,X):\n        '''\n        Transforms columns of X specified in self.columns using\n        LabelEncoder(). If no columns specified, transforms all\n        columns in X.\n        '''\n        output = X.copy()\n        if self.columns is not None:\n            for col in self.columns:\n                output[col] = LabelEncoder().fit_transform(output[col])\n        else:\n            for colname,col in output.iteritems():\n                output[colname] = LabelEncoder().fit_transform(col)\n        return output\n\n    def fit_transform(self,X,y=None):\n        return self.fit(X,y).transform(X)\n", "MultiColumnLabelEncoder(columns = ['fruit','color']).fit_transform(fruit_data)\n", "MultiColumnLabelEncoder().fit_transform(fruit_data.drop('weight',axis=1))\n", "encoding_pipeline = Pipeline([\n    ('encoding',MultiColumnLabelEncoder(columns=['fruit','color']))\n    # add more pipeline steps as needed\n])\nencoding_pipeline.fit_transform(fruit_data)\n"], "is_accepted": false}, {"answer_content": "Since scikit-learn 0.20 you can use sklearn.compose.ColumnTransformer and sklearn.preprocessing.OneHotEncoder:\nIf you only have categorical variables, OneHotEncoder directly:\nfrom sklearn.preprocessing import OneHotEncoder\n\nOneHotEncoder(handle_unknown='ignore').fit_transform(df)\n\nIf you have heterogeneously typed features:\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import OneHotEncoder\n\ncategorical_columns = ['pets', 'owner', 'location']\nnumerical_columns = ['age', 'weigth', 'height']\ncolumn_trans = make_column_transformer(\n    (categorical_columns, OneHotEncoder(handle_unknown='ignore'),\n    (numerical_columns, RobustScaler())\ncolumn_trans.fit_transform(df)\n\nMore options in the documentation: http://scikit-learn.org/stable/modules/compose.html#columntransformer-for-heterogeneous-data", "answer_comment": ["inverse_transform() is not supported on ColumnTransformer though. At least, not for the moment: github.com/scikit-learn/scikit-learn/issues/11463. That's a big disadvantage for my application, and will probably also be for others.", "Although ColumnTransformer is a great suggestion, this code does not run (imbalanced parentheses, column_transformer does not/no longer works that way)", "I've proposed an edit to the original answer to fix the code"], "answer_score": "34", "answer_code_list": ["from sklearn.preprocessing import OneHotEncoder\n\nOneHotEncoder(handle_unknown='ignore').fit_transform(df)\n", "from sklearn.compose import make_column_transformer\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import OneHotEncoder\n\ncategorical_columns = ['pets', 'owner', 'location']\nnumerical_columns = ['age', 'weigth', 'height']\ncolumn_trans = make_column_transformer(\n    (categorical_columns, OneHotEncoder(handle_unknown='ignore'),\n    (numerical_columns, RobustScaler())\ncolumn_trans.fit_transform(df)\n"], "is_accepted": false}, {"answer_content": "We don't need a LabelEncoder.\nYou can convert the columns to categoricals and then get their codes.  I used a dictionary comprehension below to apply this process to every column and wrap the result back into a dataframe of the same shape with identical indices and column names.\n>>> pd.DataFrame({col: df[col].astype('category').cat.codes for col in df}, index=df.index)\n   location  owner  pets\n0         1      1     0\n1         0      2     1\n2         0      0     0\n3         1      1     2\n4         1      3     1\n5         0      2     1\n\nTo create a mapping dictionary, you can just enumerate the categories using a dictionary comprehension:\n>>> {col: {n: cat for n, cat in enumerate(df[col].astype('category').cat.categories)} \n     for col in df}\n\n{'location': {0: 'New_York', 1: 'San_Diego'},\n 'owner': {0: 'Brick', 1: 'Champ', 2: 'Ron', 3: 'Veronica'},\n 'pets': {0: 'cat', 1: 'dog', 2: 'monkey'}}", "answer_comment": ["If i want to go back (reverse) for one column (example target variable : Y) how do i do it ?", "Nice one Alexander! I like this a lot!!"], "answer_score": "21", "answer_code_list": [">>> pd.DataFrame({col: df[col].astype('category').cat.codes for col in df}, index=df.index)\n   location  owner  pets\n0         1      1     0\n1         0      2     1\n2         0      0     0\n3         1      1     2\n4         1      3     1\n5         0      2     1\n", ">>> {col: {n: cat for n, cat in enumerate(df[col].astype('category').cat.categories)} \n     for col in df}\n\n{'location': {0: 'New_York', 1: 'San_Diego'},\n 'owner': {0: 'Brick', 1: 'Champ', 2: 'Ron', 3: 'Veronica'},\n 'pets': {0: 'cat', 1: 'dog', 2: 'monkey'}}\n"], "is_accepted": false}, {"answer_content": "this does not directly answer your question (for which Naputipulu Jon and PriceHardman have fantastic replies)\nHowever, for the purpose of a few classification tasks etc. you could use\npandas.get_dummies(input_df) \n\nthis can input dataframe with categorical data and return a dataframe with binary values. variable values are encoded into column names in the resulting dataframe. more", "answer_comment": [], "answer_score": "13", "answer_code_list": ["pandas.get_dummies(input_df) \n"], "is_accepted": false}, {"answer_content": "This is a year-and-a-half after the fact, but I too, needed to be able to .transform() multiple pandas dataframe columns at once (and be able to .inverse_transform() them as well). This expands upon the excellent suggestion of @PriceHardman above:\nclass MultiColumnLabelEncoder(LabelEncoder):\n    \"\"\"\n    Wraps sklearn LabelEncoder functionality for use on multiple columns of a\n    pandas dataframe.\n\n    \"\"\"\n    def __init__(self, columns=None):\n        self.columns = columns\n\n    def fit(self, dframe):\n        \"\"\"\n        Fit label encoder to pandas columns.\n\n        Access individual column classes via indexig `self.all_classes_`\n\n        Access individual column encoders via indexing\n        `self.all_encoders_`\n        \"\"\"\n        # if columns are provided, iterate through and get `classes_`\n        if self.columns is not None:\n            # ndarray to hold LabelEncoder().classes_ for each\n            # column; should match the shape of specified `columns`\n            self.all_classes_ = np.ndarray(shape=self.columns.shape,\n                                           dtype=object)\n            self.all_encoders_ = np.ndarray(shape=self.columns.shape,\n                                            dtype=object)\n            for idx, column in enumerate(self.columns):\n                # fit LabelEncoder to get `classes_` for the column\n                le = LabelEncoder()\n                le.fit(dframe.loc[:, column].values)\n                # append the `classes_` to our ndarray container\n                self.all_classes_[idx] = (column,\n                                          np.array(le.classes_.tolist(),\n                                                  dtype=object))\n                # append this column's encoder\n                self.all_encoders_[idx] = le\n        else:\n            # no columns specified; assume all are to be encoded\n            self.columns = dframe.iloc[:, :].columns\n            self.all_classes_ = np.ndarray(shape=self.columns.shape,\n                                           dtype=object)\n            for idx, column in enumerate(self.columns):\n                le = LabelEncoder()\n                le.fit(dframe.loc[:, column].values)\n                self.all_classes_[idx] = (column,\n                                          np.array(le.classes_.tolist(),\n                                                  dtype=object))\n                self.all_encoders_[idx] = le\n        return self\n\n    def fit_transform(self, dframe):\n        \"\"\"\n        Fit label encoder and return encoded labels.\n\n        Access individual column classes via indexing\n        `self.all_classes_`\n\n        Access individual column encoders via indexing\n        `self.all_encoders_`\n\n        Access individual column encoded labels via indexing\n        `self.all_labels_`\n        \"\"\"\n        # if columns are provided, iterate through and get `classes_`\n        if self.columns is not None:\n            # ndarray to hold LabelEncoder().classes_ for each\n            # column; should match the shape of specified `columns`\n            self.all_classes_ = np.ndarray(shape=self.columns.shape,\n                                           dtype=object)\n            self.all_encoders_ = np.ndarray(shape=self.columns.shape,\n                                            dtype=object)\n            self.all_labels_ = np.ndarray(shape=self.columns.shape,\n                                          dtype=object)\n            for idx, column in enumerate(self.columns):\n                # instantiate LabelEncoder\n                le = LabelEncoder()\n                # fit and transform labels in the column\n                dframe.loc[:, column] =\\\n                    le.fit_transform(dframe.loc[:, column].values)\n                # append the `classes_` to our ndarray container\n                self.all_classes_[idx] = (column,\n                                          np.array(le.classes_.tolist(),\n                                                  dtype=object))\n                self.all_encoders_[idx] = le\n                self.all_labels_[idx] = le\n        else:\n            # no columns specified; assume all are to be encoded\n            self.columns = dframe.iloc[:, :].columns\n            self.all_classes_ = np.ndarray(shape=self.columns.shape,\n                                           dtype=object)\n            for idx, column in enumerate(self.columns):\n                le = LabelEncoder()\n                dframe.loc[:, column] = le.fit_transform(\n                        dframe.loc[:, column].values)\n                self.all_classes_[idx] = (column,\n                                          np.array(le.classes_.tolist(),\n                                                  dtype=object))\n                self.all_encoders_[idx] = le\n        return dframe.loc[:, self.columns].values\n\n    def transform(self, dframe):\n        \"\"\"\n        Transform labels to normalized encoding.\n        \"\"\"\n        if self.columns is not None:\n            for idx, column in enumerate(self.columns):\n                dframe.loc[:, column] = self.all_encoders_[\n                    idx].transform(dframe.loc[:, column].values)\n        else:\n            self.columns = dframe.iloc[:, :].columns\n            for idx, column in enumerate(self.columns):\n                dframe.loc[:, column] = self.all_encoders_[idx]\\\n                    .transform(dframe.loc[:, column].values)\n        return dframe.loc[:, self.columns].values\n\n    def inverse_transform(self, dframe):\n        \"\"\"\n        Transform labels back to original encoding.\n        \"\"\"\n        if self.columns is not None:\n            for idx, column in enumerate(self.columns):\n                dframe.loc[:, column] = self.all_encoders_[idx]\\\n                    .inverse_transform(dframe.loc[:, column].values)\n        else:\n            self.columns = dframe.iloc[:, :].columns\n            for idx, column in enumerate(self.columns):\n                dframe.loc[:, column] = self.all_encoders_[idx]\\\n                    .inverse_transform(dframe.loc[:, column].values)\n        return dframe.loc[:, self.columns].values\n\nExample:\nIf df and df_copy() are mixed-type pandas dataframes, you can apply the MultiColumnLabelEncoder() to the dtype=object columns in the following way:\n# get `object` columns\ndf_object_columns = df.iloc[:, :].select_dtypes(include=['object']).columns\ndf_copy_object_columns = df_copy.iloc[:, :].select_dtypes(include=['object']).columns\n\n# instantiate `MultiColumnLabelEncoder`\nmcle = MultiColumnLabelEncoder(columns=object_columns)\n\n# fit to `df` data\nmcle.fit(df)\n\n# transform the `df` data\nmcle.transform(df)\n\n# returns output like below\narray([[1, 0, 0, ..., 1, 1, 0],\n       [0, 5, 1, ..., 1, 1, 2],\n       [1, 1, 1, ..., 1, 1, 2],\n       ..., \n       [3, 5, 1, ..., 1, 1, 2],\n\n# transform `df_copy` data\nmcle.transform(df_copy)\n\n# returns output like below (assuming the respective columns \n# of `df_copy` contain the same unique values as that particular \n# column in `df`\narray([[1, 0, 0, ..., 1, 1, 0],\n       [0, 5, 1, ..., 1, 1, 2],\n       [1, 1, 1, ..., 1, 1, 2],\n       ..., \n       [3, 5, 1, ..., 1, 1, 2],\n\n# inverse `df` data\nmcle.inverse_transform(df)\n\n# outputs data like below\narray([['August', 'Friday', '2013', ..., 'N', 'N', 'CA'],\n       ['April', 'Tuesday', '2014', ..., 'N', 'N', 'NJ'],\n       ['August', 'Monday', '2014', ..., 'N', 'N', 'NJ'],\n       ..., \n       ['February', 'Tuesday', '2014', ..., 'N', 'N', 'NJ'],\n       ['April', 'Tuesday', '2014', ..., 'N', 'N', 'NJ'],\n       ['March', 'Tuesday', '2013', ..., 'N', 'N', 'NJ']], dtype=object)\n\n# inverse `df_copy` data\nmcle.inverse_transform(df_copy)\n\n# outputs data like below\narray([['August', 'Friday', '2013', ..., 'N', 'N', 'CA'],\n       ['April', 'Tuesday', '2014', ..., 'N', 'N', 'NJ'],\n       ['August', 'Monday', '2014', ..., 'N', 'N', 'NJ'],\n       ..., \n       ['February', 'Tuesday', '2014', ..., 'N', 'N', 'NJ'],\n       ['April', 'Tuesday', '2014', ..., 'N', 'N', 'NJ'],\n       ['March', 'Tuesday', '2013', ..., 'N', 'N', 'NJ']], dtype=object)\n\nYou can access individual column classes, column labels, and column encoders used to fit each column via indexing:\nmcle.all_classes_\nmcle.all_encoders_\nmcle.all_labels_", "answer_comment": ["Hi Jason, mcle.all_labels_ does not appear to work (Python 3.5, Conda 4.3.29, Sklearn 0.18.1, Pandas 0.20.1. I get: AttributeError: 'MultiColumnLabelEncoder' object has no attribute 'all_labels_'", "@Jason Hi, sorry, I didn't see this until today :/ but if I had to guess, I would say that you just used the fit method from above which won't actually produce any labels until you apply it (transform / fit_transform) to the data.", "I think you need to put a better example - I couldn't rerun all your codes."], "answer_score": "13", "answer_code_list": ["class MultiColumnLabelEncoder(LabelEncoder):\n    \"\"\"\n    Wraps sklearn LabelEncoder functionality for use on multiple columns of a\n    pandas dataframe.\n\n    \"\"\"\n    def __init__(self, columns=None):\n        self.columns = columns\n\n    def fit(self, dframe):\n        \"\"\"\n        Fit label encoder to pandas columns.\n\n        Access individual column classes via indexig `self.all_classes_`\n\n        Access individual column encoders via indexing\n        `self.all_encoders_`\n        \"\"\"\n        # if columns are provided, iterate through and get `classes_`\n        if self.columns is not None:\n            # ndarray to hold LabelEncoder().classes_ for each\n            # column; should match the shape of specified `columns`\n            self.all_classes_ = np.ndarray(shape=self.columns.shape,\n                                           dtype=object)\n            self.all_encoders_ = np.ndarray(shape=self.columns.shape,\n                                            dtype=object)\n            for idx, column in enumerate(self.columns):\n                # fit LabelEncoder to get `classes_` for the column\n                le = LabelEncoder()\n                le.fit(dframe.loc[:, column].values)\n                # append the `classes_` to our ndarray container\n                self.all_classes_[idx] = (column,\n                                          np.array(le.classes_.tolist(),\n                                                  dtype=object))\n                # append this column's encoder\n                self.all_encoders_[idx] = le\n        else:\n            # no columns specified; assume all are to be encoded\n            self.columns = dframe.iloc[:, :].columns\n            self.all_classes_ = np.ndarray(shape=self.columns.shape,\n                                           dtype=object)\n            for idx, column in enumerate(self.columns):\n                le = LabelEncoder()\n                le.fit(dframe.loc[:, column].values)\n                self.all_classes_[idx] = (column,\n                                          np.array(le.classes_.tolist(),\n                                                  dtype=object))\n                self.all_encoders_[idx] = le\n        return self\n\n    def fit_transform(self, dframe):\n        \"\"\"\n        Fit label encoder and return encoded labels.\n\n        Access individual column classes via indexing\n        `self.all_classes_`\n\n        Access individual column encoders via indexing\n        `self.all_encoders_`\n\n        Access individual column encoded labels via indexing\n        `self.all_labels_`\n        \"\"\"\n        # if columns are provided, iterate through and get `classes_`\n        if self.columns is not None:\n            # ndarray to hold LabelEncoder().classes_ for each\n            # column; should match the shape of specified `columns`\n            self.all_classes_ = np.ndarray(shape=self.columns.shape,\n                                           dtype=object)\n            self.all_encoders_ = np.ndarray(shape=self.columns.shape,\n                                            dtype=object)\n            self.all_labels_ = np.ndarray(shape=self.columns.shape,\n                                          dtype=object)\n            for idx, column in enumerate(self.columns):\n                # instantiate LabelEncoder\n                le = LabelEncoder()\n                # fit and transform labels in the column\n                dframe.loc[:, column] =\\\n                    le.fit_transform(dframe.loc[:, column].values)\n                # append the `classes_` to our ndarray container\n                self.all_classes_[idx] = (column,\n                                          np.array(le.classes_.tolist(),\n                                                  dtype=object))\n                self.all_encoders_[idx] = le\n                self.all_labels_[idx] = le\n        else:\n            # no columns specified; assume all are to be encoded\n            self.columns = dframe.iloc[:, :].columns\n            self.all_classes_ = np.ndarray(shape=self.columns.shape,\n                                           dtype=object)\n            for idx, column in enumerate(self.columns):\n                le = LabelEncoder()\n                dframe.loc[:, column] = le.fit_transform(\n                        dframe.loc[:, column].values)\n                self.all_classes_[idx] = (column,\n                                          np.array(le.classes_.tolist(),\n                                                  dtype=object))\n                self.all_encoders_[idx] = le\n        return dframe.loc[:, self.columns].values\n\n    def transform(self, dframe):\n        \"\"\"\n        Transform labels to normalized encoding.\n        \"\"\"\n        if self.columns is not None:\n            for idx, column in enumerate(self.columns):\n                dframe.loc[:, column] = self.all_encoders_[\n                    idx].transform(dframe.loc[:, column].values)\n        else:\n            self.columns = dframe.iloc[:, :].columns\n            for idx, column in enumerate(self.columns):\n                dframe.loc[:, column] = self.all_encoders_[idx]\\\n                    .transform(dframe.loc[:, column].values)\n        return dframe.loc[:, self.columns].values\n\n    def inverse_transform(self, dframe):\n        \"\"\"\n        Transform labels back to original encoding.\n        \"\"\"\n        if self.columns is not None:\n            for idx, column in enumerate(self.columns):\n                dframe.loc[:, column] = self.all_encoders_[idx]\\\n                    .inverse_transform(dframe.loc[:, column].values)\n        else:\n            self.columns = dframe.iloc[:, :].columns\n            for idx, column in enumerate(self.columns):\n                dframe.loc[:, column] = self.all_encoders_[idx]\\\n                    .inverse_transform(dframe.loc[:, column].values)\n        return dframe.loc[:, self.columns].values\n", "# get `object` columns\ndf_object_columns = df.iloc[:, :].select_dtypes(include=['object']).columns\ndf_copy_object_columns = df_copy.iloc[:, :].select_dtypes(include=['object']).columns\n\n# instantiate `MultiColumnLabelEncoder`\nmcle = MultiColumnLabelEncoder(columns=object_columns)\n\n# fit to `df` data\nmcle.fit(df)\n\n# transform the `df` data\nmcle.transform(df)\n\n# returns output like below\narray([[1, 0, 0, ..., 1, 1, 0],\n       [0, 5, 1, ..., 1, 1, 2],\n       [1, 1, 1, ..., 1, 1, 2],\n       ..., \n       [3, 5, 1, ..., 1, 1, 2],\n\n# transform `df_copy` data\nmcle.transform(df_copy)\n\n# returns output like below (assuming the respective columns \n# of `df_copy` contain the same unique values as that particular \n# column in `df`\narray([[1, 0, 0, ..., 1, 1, 0],\n       [0, 5, 1, ..., 1, 1, 2],\n       [1, 1, 1, ..., 1, 1, 2],\n       ..., \n       [3, 5, 1, ..., 1, 1, 2],\n\n# inverse `df` data\nmcle.inverse_transform(df)\n\n# outputs data like below\narray([['August', 'Friday', '2013', ..., 'N', 'N', 'CA'],\n       ['April', 'Tuesday', '2014', ..., 'N', 'N', 'NJ'],\n       ['August', 'Monday', '2014', ..., 'N', 'N', 'NJ'],\n       ..., \n       ['February', 'Tuesday', '2014', ..., 'N', 'N', 'NJ'],\n       ['April', 'Tuesday', '2014', ..., 'N', 'N', 'NJ'],\n       ['March', 'Tuesday', '2013', ..., 'N', 'N', 'NJ']], dtype=object)\n\n# inverse `df_copy` data\nmcle.inverse_transform(df_copy)\n\n# outputs data like below\narray([['August', 'Friday', '2013', ..., 'N', 'N', 'CA'],\n       ['April', 'Tuesday', '2014', ..., 'N', 'N', 'NJ'],\n       ['August', 'Monday', '2014', ..., 'N', 'N', 'NJ'],\n       ..., \n       ['February', 'Tuesday', '2014', ..., 'N', 'N', 'NJ'],\n       ['April', 'Tuesday', '2014', ..., 'N', 'N', 'NJ'],\n       ['March', 'Tuesday', '2013', ..., 'N', 'N', 'NJ']], dtype=object)\n"], "is_accepted": false}, {"answer_content": "It is possible to do this all in pandas directly and is well-suited for a unique ability of the replace method.\nFirst, let's make a dictionary of dictionaries mapping the columns and their values to their new replacement values.\ntransform_dict = {}\nfor col in df.columns:\n    cats = pd.Categorical(df[col]).categories\n    d = {}\n    for i, cat in enumerate(cats):\n        d[cat] = i\n    transform_dict[col] = d\n\ntransform_dict\n{'location': {'New_York': 0, 'San_Diego': 1},\n 'owner': {'Brick': 0, 'Champ': 1, 'Ron': 2, 'Veronica': 3},\n 'pets': {'cat': 0, 'dog': 1, 'monkey': 2}}\n\nSince this will always be a one to one mapping, we can invert the inner dictionary to get a mapping of the new values back to the original.\ninverse_transform_dict = {}\nfor col, d in transform_dict.items():\n    inverse_transform_dict[col] = {v:k for k, v in d.items()}\n\ninverse_transform_dict\n{'location': {0: 'New_York', 1: 'San_Diego'},\n 'owner': {0: 'Brick', 1: 'Champ', 2: 'Ron', 3: 'Veronica'},\n 'pets': {0: 'cat', 1: 'dog', 2: 'monkey'}}\n\nNow, we can use the unique ability of the replace method to take a nested list of dictionaries and use the outer keys as the columns, and the inner keys as the values we would like to replace.\ndf.replace(transform_dict)\n   location  owner  pets\n0         1      1     0\n1         0      2     1\n2         0      0     0\n3         1      1     2\n4         1      3     1\n5         0      2     1\n\nWe can easily go back to the original by again chaining the replace method\ndf.replace(transform_dict).replace(inverse_transform_dict)\n    location     owner    pets\n0  San_Diego     Champ     cat\n1   New_York       Ron     dog\n2   New_York     Brick     cat\n3  San_Diego     Champ  monkey\n4  San_Diego  Veronica     dog\n5   New_York       Ron     dog", "answer_comment": [], "answer_score": "11", "answer_code_list": ["transform_dict = {}\nfor col in df.columns:\n    cats = pd.Categorical(df[col]).categories\n    d = {}\n    for i, cat in enumerate(cats):\n        d[cat] = i\n    transform_dict[col] = d\n\ntransform_dict\n{'location': {'New_York': 0, 'San_Diego': 1},\n 'owner': {'Brick': 0, 'Champ': 1, 'Ron': 2, 'Veronica': 3},\n 'pets': {'cat': 0, 'dog': 1, 'monkey': 2}}\n", "inverse_transform_dict = {}\nfor col, d in transform_dict.items():\n    inverse_transform_dict[col] = {v:k for k, v in d.items()}\n\ninverse_transform_dict\n{'location': {0: 'New_York', 1: 'San_Diego'},\n 'owner': {0: 'Brick', 1: 'Champ', 2: 'Ron', 3: 'Veronica'},\n 'pets': {0: 'cat', 1: 'dog', 2: 'monkey'}}\n", "df.replace(transform_dict)\n   location  owner  pets\n0         1      1     0\n1         0      2     1\n2         0      0     0\n3         1      1     2\n4         1      3     1\n5         0      2     1\n", "df.replace(transform_dict).replace(inverse_transform_dict)\n    location     owner    pets\n0  San_Diego     Champ     cat\n1   New_York       Ron     dog\n2   New_York     Brick     cat\n3  San_Diego     Champ  monkey\n4  San_Diego  Veronica     dog\n5   New_York       Ron     dog\n"], "is_accepted": false}, {"answer_content": "No, LabelEncoder does not do this. It takes 1-d arrays of class labels and produces 1-d arrays. It's designed to handle class labels in classification problems, not arbitrary data, and any attempt to force it into other uses will require code to transform the actual problem to the problem it solves (and the solution back to the original space).", "answer_comment": ["Ok, given this, what is your suggestion on the best way I can encode string labels by an entire DataFrame at a time?", "@Bryan Look at the LabelEncoder code and adapt it. I don't use Pandas myself, so I don't know how hard that will be.", "I'll let other pandas folks take a crack at this question too -- I'm sure I'm not the only person with this challenge, so I hope there might be a pre-built solution out there."], "answer_score": "7", "answer_code_list": [], "is_accepted": false}, {"answer_content": "Assuming you are simply trying to get a sklearn.preprocessing.LabelEncoder() object that can be used to represent your columns, all you have to do is:\nle.fit(df.columns)\n\nIn the above code you will have a unique number corresponding to each column.\nMore precisely, you will have a 1:1 mapping of df.columns to le.transform(df.columns.get_values()). To get a column's encoding, simply pass it to le.transform(...). As an example, the following will get the encoding for each column:\nle.transform(df.columns.get_values())\n\nAssuming you want to create a sklearn.preprocessing.LabelEncoder() object for all of your row labels you can do the following:\nle.fit([y for x in df.get_values() for y in x])\n\nIn this case, you most likely have non-unique row labels (as shown in your question). To see what classes the encoder created you can do le.classes_. You'll note that this should have the same elements as in set(y for x in df.get_values() for y in x). Once again to convert a row label to an encoded label use le.transform(...). As an example, if you want to retrieve the label for the first column in the df.columns array and the first row, you could do this:\nle.transform([df.get_value(0, df.columns[0])])\n\nThe question you had in your comment is a bit more complicated, but can still\nbe accomplished:\nle.fit([str(z) for z in set((x[0], y) for x in df.iteritems() for y in x[1])])\n\nThe above code does the following:\n\nMake a unique combination of all of the pairs of (column, row)\nRepresent each pair as a string version of the tuple. This is a workaround to overcome the LabelEncoder class not supporting tuples as a class name.\nFits the new items to the LabelEncoder.\n\nNow to use this new model it's a bit more complicated. Assuming we want to extract the representation for the same item we looked up in the previous example (the first column in df.columns and the first row), we can do this:\nle.transform([str((df.columns[0], df.get_value(0, df.columns[0])))])\n\nRemember that each lookup is now a string representation of a tuple that\ncontains the (column, row).", "answer_comment": [], "answer_score": "7", "answer_code_list": ["le.fit(df.columns)\n", "le.transform(df.columns.get_values())\n", "le.fit([y for x in df.get_values() for y in x])\n", "le.transform([df.get_value(0, df.columns[0])])\n", "le.fit([str(z) for z in set((x[0], y) for x in df.iteritems() for y in x[1])])\n", "le.transform([str((df.columns[0], df.get_value(0, df.columns[0])))])\n"], "is_accepted": false}, {"answer_content": "Here is the script\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ncol_list = df.select_dtypes(include = \"object\").columns\nfor colsn in col_list:\n    df[colsn] = le.fit_transform(df[colsn].astype(str))", "answer_comment": [], "answer_score": "6", "answer_code_list": ["from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ncol_list = df.select_dtypes(include = \"object\").columns\nfor colsn in col_list:\n    df[colsn] = le.fit_transform(df[colsn].astype(str))\n"], "is_accepted": false}, {"answer_content": "If you have numerical and categorical both type of data in dataframe \nYou can use : here X is my dataframe having categorical and numerical both variables\nfrom sklearn import preprocessing\nle = preprocessing.LabelEncoder()\n\nfor i in range(0,X.shape[1]):\n    if X.dtypes[i]=='object':\n        X[X.columns[i]] = le.fit_transform(X[X.columns[i]])\n\nNote: This technique is good if you are not interested in converting them back.", "answer_comment": [], "answer_score": "5", "answer_code_list": ["from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\n\nfor i in range(0,X.shape[1]):\n    if X.dtypes[i]=='object':\n        X[X.columns[i]] = le.fit_transform(X[X.columns[i]])\n"], "is_accepted": false}, {"answer_content": "After lots of search and experimentation with some answers here and elsewhere, I think your answer is here:\n\npd.DataFrame(columns=df.columns,\n  data=LabelEncoder().fit_transform(df.values.flatten()).reshape(df.shape))\n\nThis will preserve category names across columns:\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\ndf = pd.DataFrame([['A','B','C','D','E','F','G','I','K','H'],\n                   ['A','E','H','F','G','I','K','','',''],\n                   ['A','C','I','F','H','G','','','','']], \n                  columns=['A1', 'A2', 'A3','A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10'])\n\npd.DataFrame(columns=df.columns, data=LabelEncoder().fit_transform(df.values.flatten()).reshape(df.shape))\n\n    A1  A2  A3  A4  A5  A6  A7  A8  A9  A10\n0   1   2   3   4   5   6   7   9   10  8\n1   1   5   8   6   7   9   10  0   0   0\n2   1   3   9   6   8   7   0   0   0   0", "answer_comment": [], "answer_score": "5", "answer_code_list": ["import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\ndf = pd.DataFrame([['A','B','C','D','E','F','G','I','K','H'],\n                   ['A','E','H','F','G','I','K','','',''],\n                   ['A','C','I','F','H','G','','','','']], \n                  columns=['A1', 'A2', 'A3','A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10'])\n\npd.DataFrame(columns=df.columns, data=LabelEncoder().fit_transform(df.values.flatten()).reshape(df.shape))\n\n    A1  A2  A3  A4  A5  A6  A7  A8  A9  A10\n0   1   2   3   4   5   6   7   9   10  8\n1   1   5   8   6   7   9   10  0   0   0\n2   1   3   9   6   8   7   0   0   0   0\n"], "is_accepted": false}, {"answer_content": "I checked the source code (https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/preprocessing/label.py) of LabelEncoder. It was based on a set of numpy transformation, which one of those is np.unique(). And this function only takes 1-d array input. (correct me if I am wrong). \n\nVery Rough ideas...\nfirst, identify which columns needed LabelEncoder, then loop through each column. \n\ndef cat_var(df): \n    \"\"\"Identify categorical features. \n\n    Parameters\n    ----------\n    df: original df after missing operations \n\n    Returns\n    -------\n    cat_var_df: summary df with col index and col name for all categorical vars\n    \"\"\"\n    col_type = df.dtypes\n    col_names = list(df)\n\n    cat_var_index = [i for i, x in enumerate(col_type) if x=='object']\n    cat_var_name = [x for i, x in enumerate(col_names) if i in cat_var_index]\n\n    cat_var_df = pd.DataFrame({'cat_ind': cat_var_index, \n                               'cat_name': cat_var_name})\n\n    return cat_var_df\n\n\n\nfrom sklearn.preprocessing import LabelEncoder \n\ndef column_encoder(df, cat_var_list):\n    \"\"\"Encoding categorical feature in the dataframe\n\n    Parameters\n    ----------\n    df: input dataframe \n    cat_var_list: categorical feature index and name, from cat_var function\n\n    Return\n    ------\n    df: new dataframe where categorical features are encoded\n    label_list: classes_ attribute for all encoded features \n    \"\"\"\n\n    label_list = []\n    cat_var_df = cat_var(df)\n    cat_list = cat_var_df.loc[:, 'cat_name']\n\n    for index, cat_feature in enumerate(cat_list): \n\n        le = LabelEncoder()\n\n        le.fit(df.loc[:, cat_feature])    \n        label_list.append(list(le.classes_))\n\n        df.loc[:, cat_feature] = le.transform(df.loc[:, cat_feature])\n\n    return df, label_list\n\n\nThe returned df would be the one after encoding, and label_list will show you what all those values means in the corresponding column. \nThis is a snippet from a data process script I wrote for work. Let me know if you think there could be any further improvement. \n\n\nEDIT: \nJust want to mention here that the methods above work with data frame with no missing the best. Not sure how it is working toward data frame contains missing data. (I had a deal with missing procedure before execute above methods)", "answer_comment": [], "answer_score": "5", "answer_code_list": ["def cat_var(df): \n    \"\"\"Identify categorical features. \n\n    Parameters\n    ----------\n    df: original df after missing operations \n\n    Returns\n    -------\n    cat_var_df: summary df with col index and col name for all categorical vars\n    \"\"\"\n    col_type = df.dtypes\n    col_names = list(df)\n\n    cat_var_index = [i for i, x in enumerate(col_type) if x=='object']\n    cat_var_name = [x for i, x in enumerate(col_names) if i in cat_var_index]\n\n    cat_var_df = pd.DataFrame({'cat_ind': cat_var_index, \n                               'cat_name': cat_var_name})\n\n    return cat_var_df\n\n\n\nfrom sklearn.preprocessing import LabelEncoder \n\ndef column_encoder(df, cat_var_list):\n    \"\"\"Encoding categorical feature in the dataframe\n\n    Parameters\n    ----------\n    df: input dataframe \n    cat_var_list: categorical feature index and name, from cat_var function\n\n    Return\n    ------\n    df: new dataframe where categorical features are encoded\n    label_list: classes_ attribute for all encoded features \n    \"\"\"\n\n    label_list = []\n    cat_var_df = cat_var(df)\n    cat_list = cat_var_df.loc[:, 'cat_name']\n\n    for index, cat_feature in enumerate(cat_list): \n\n        le = LabelEncoder()\n\n        le.fit(df.loc[:, cat_feature])    \n        label_list.append(list(le.classes_))\n\n        df.loc[:, cat_feature] = le.transform(df.loc[:, cat_feature])\n\n    return df, label_list\n"], "is_accepted": false}, {"answer_content": "A short way to LabelEncoder() multiple columns with a dict():\n\nfrom sklearn.preprocessing import LabelEncoder\nle_dict = {col: LabelEncoder() for col in columns }\nfor col in columns:\n    le_dict[col].fit_transform(df[col])\n\nand you can use this le_dict to labelEncode any other column:\n\nle_dict[col].transform(df_another[col])", "answer_comment": [], "answer_score": "4", "answer_code_list": ["from sklearn.preprocessing import LabelEncoder\nle_dict = {col: LabelEncoder() for col in columns }\nfor col in columns:\n    le_dict[col].fit_transform(df[col])\n", "le_dict[col].transform(df_another[col])\n"], "is_accepted": false}, {"answer_content": "Instead of LabelEncoder we can use OrdinalEncoder from scikit learn, which allows multi-column encoding.\n\nEncode categorical features as an integer array.\nThe input to this transformer should be an array-like of integers or strings, denoting the values taken on by categorical (discrete) features. The features are converted to ordinal integers. This results in a single column of integers (0 to n_categories - 1) per feature.\n\n>>> from sklearn.preprocessing import OrdinalEncoder\n>>> enc = OrdinalEncoder()\n>>> X = [['Male', 1], ['Female', 3], ['Female', 2]]\n>>> enc.fit(X)\nOrdinalEncoder()\n>>> enc.categories_\n[array(['Female', 'Male'], dtype=object), array([1, 2, 3], dtype=object)]\n>>> enc.transform([['Female', 3], ['Male', 1]])\narray([[0., 2.],\n       [1., 0.]])\n\nBoth the description and example were copied from its documentation page which you can find here:\nhttps://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html#sklearn.preprocessing.OrdinalEncoder", "answer_comment": ["This should be the way to go as of scikit-learn 0.20. Thank you for suggesting it!"], "answer_score": "4", "answer_code_list": [">>> from sklearn.preprocessing import OrdinalEncoder\n>>> enc = OrdinalEncoder()\n>>> X = [['Male', 1], ['Female', 3], ['Female', 2]]\n>>> enc.fit(X)\nOrdinalEncoder()\n>>> enc.categories_\n[array(['Female', 'Male'], dtype=object), array([1, 2, 3], dtype=object)]\n>>> enc.transform([['Female', 3], ['Male', 1]])\narray([[0., 2.],\n       [1., 0.]])\n"], "is_accepted": false}, {"answer_content": "Using Neuraxle\n\nTLDR; You here can use the FlattenForEach wrapper class to simply transform your df like: FlattenForEach(LabelEncoder(), then_unflatten=True).fit_transform(df). \n\nWith this method, your label encoder will be able to fit and transform within a regular scikit-learn Pipeline. Let's simply import: \nfrom sklearn.preprocessing import LabelEncoder\nfrom neuraxle.steps.column_transformer import ColumnTransformer\nfrom neuraxle.steps.loop import FlattenForEach\n\nSame shared encoder for columns:\nHere is how one shared LabelEncoder will be applied on all the data to encode it:\n    p = FlattenForEach(LabelEncoder(), then_unflatten=True)\n\nResult: \n    p, predicted_output = p.fit_transform(df.values)\n    expected_output = np.array([\n        [6, 7, 6, 8, 7, 7],\n        [1, 3, 0, 1, 5, 3],\n        [4, 2, 2, 4, 4, 2]\n    ]).transpose()\n    assert np.array_equal(predicted_output, expected_output)\n\nDifferent encoders per column:\nAnd here is how a first standalone LabelEncoder will be applied on the pets, and a second will be shared for the columns owner and location. So to be precise, we here have a mix of different and shared label encoders:\n    p = ColumnTransformer([\n        # A different encoder will be used for column 0 with name \"pets\":\n        (0, FlattenForEach(LabelEncoder(), then_unflatten=True)),\n        # A shared encoder will be used for column 1 and 2, \"owner\" and \"location\":\n        ([1, 2], FlattenForEach(LabelEncoder(), then_unflatten=True)),\n    ], n_dimension=2)\n\nResult: \n    p, predicted_output = p.fit_transform(df.values)\n    expected_output = np.array([\n        [0, 1, 0, 2, 1, 1],\n        [1, 3, 0, 1, 5, 3],\n        [4, 2, 2, 4, 4, 2]\n    ]).transpose()\n    assert np.array_equal(predicted_output, expected_output)", "answer_comment": [], "answer_score": "3", "answer_code_list": ["from sklearn.preprocessing import LabelEncoder\nfrom neuraxle.steps.column_transformer import ColumnTransformer\nfrom neuraxle.steps.loop import FlattenForEach\n", "    p = FlattenForEach(LabelEncoder(), then_unflatten=True)\n", "    p, predicted_output = p.fit_transform(df.values)\n    expected_output = np.array([\n        [6, 7, 6, 8, 7, 7],\n        [1, 3, 0, 1, 5, 3],\n        [4, 2, 2, 4, 4, 2]\n    ]).transpose()\n    assert np.array_equal(predicted_output, expected_output)\n", "    p = ColumnTransformer([\n        # A different encoder will be used for column 0 with name \"pets\":\n        (0, FlattenForEach(LabelEncoder(), then_unflatten=True)),\n        # A shared encoder will be used for column 1 and 2, \"owner\" and \"location\":\n        ([1, 2], FlattenForEach(LabelEncoder(), then_unflatten=True)),\n    ], n_dimension=2)\n", "    p, predicted_output = p.fit_transform(df.values)\n    expected_output = np.array([\n        [0, 1, 0, 2, 1, 1],\n        [1, 3, 0, 1, 5, 3],\n        [4, 2, 2, 4, 4, 2]\n    ]).transpose()\n    assert np.array_equal(predicted_output, expected_output)\n"], "is_accepted": false}, {"answer_content": "Following up on the comments raised on the solution of @PriceHardman I would propose the following version of the class:\nclass LabelEncodingColoumns(BaseEstimator, TransformerMixin):\ndef __init__(self, cols=None):\n    pdu._is_cols_input_valid(cols)\n    self.cols = cols\n    self.les = {col: LabelEncoder() for col in cols}\n    self._is_fitted = False\n\ndef transform(self, df, **transform_params):\n    \"\"\"\n    Scaling ``cols`` of ``df`` using the fitting\n\n    Parameters\n    ----------\n    df : DataFrame\n        DataFrame to be preprocessed\n    \"\"\"\n    if not self._is_fitted:\n        raise NotFittedError(\"Fitting was not preformed\")\n    pdu._is_cols_subset_of_df_cols(self.cols, df)\n\n    df = df.copy()\n\n    label_enc_dict = {}\n    for col in self.cols:\n        label_enc_dict[col] = self.les[col].transform(df[col])\n\n    labelenc_cols = pd.DataFrame(label_enc_dict,\n        # The index of the resulting DataFrame should be assigned and\n        # equal to the one of the original DataFrame. Otherwise, upon\n        # concatenation NaNs will be introduced.\n        index=df.index\n    )\n\n    for col in self.cols:\n        df[col] = labelenc_cols[col]\n    return df\n\ndef fit(self, df, y=None, **fit_params):\n    \"\"\"\n    Fitting the preprocessing\n\n    Parameters\n    ----------\n    df : DataFrame\n        Data to use for fitting.\n        In many cases, should be ``X_train``.\n    \"\"\"\n    pdu._is_cols_subset_of_df_cols(self.cols, df)\n    for col in self.cols:\n        self.les[col].fit(df[col])\n    self._is_fitted = True\n    return self\n\nThis class fits the encoder on the training set and uses the fitted version when transforming. Initial version of the code can be found here.", "answer_comment": [], "answer_score": "2", "answer_code_list": ["class LabelEncodingColoumns(BaseEstimator, TransformerMixin):\ndef __init__(self, cols=None):\n    pdu._is_cols_input_valid(cols)\n    self.cols = cols\n    self.les = {col: LabelEncoder() for col in cols}\n    self._is_fitted = False\n\ndef transform(self, df, **transform_params):\n    \"\"\"\n    Scaling ``cols`` of ``df`` using the fitting\n\n    Parameters\n    ----------\n    df : DataFrame\n        DataFrame to be preprocessed\n    \"\"\"\n    if not self._is_fitted:\n        raise NotFittedError(\"Fitting was not preformed\")\n    pdu._is_cols_subset_of_df_cols(self.cols, df)\n\n    df = df.copy()\n\n    label_enc_dict = {}\n    for col in self.cols:\n        label_enc_dict[col] = self.les[col].transform(df[col])\n\n    labelenc_cols = pd.DataFrame(label_enc_dict,\n        # The index of the resulting DataFrame should be assigned and\n        # equal to the one of the original DataFrame. Otherwise, upon\n        # concatenation NaNs will be introduced.\n        index=df.index\n    )\n\n    for col in self.cols:\n        df[col] = labelenc_cols[col]\n    return df\n\ndef fit(self, df, y=None, **fit_params):\n    \"\"\"\n    Fitting the preprocessing\n\n    Parameters\n    ----------\n    df : DataFrame\n        Data to use for fitting.\n        In many cases, should be ``X_train``.\n    \"\"\"\n    pdu._is_cols_subset_of_df_cols(self.cols, df)\n    for col in self.cols:\n        self.les[col].fit(df[col])\n    self._is_fitted = True\n    return self\n"], "is_accepted": false}, {"answer_content": "if we have single column to do the label encoding and its inverse transform its easy how to do it when there are multiple columns in python \ndef stringtocategory(dataset):\n    '''\n    @author puja.sharma\n    @see The function label encodes the object type columns and gives label      encoded and inverse tranform of the label encoded data\n    @param dataset dataframe on whoes column the label encoding has to be done\n    @return label encoded and inverse tranform of the label encoded data.\n   ''' \n   data_original = dataset[:]\n   data_tranformed = dataset[:]\n   for y in dataset.columns:\n       #check the dtype of the column object type contains strings or chars\n       if (dataset[y].dtype == object):\n          print(\"The string type features are  : \" + y)\n          le = preprocessing.LabelEncoder()\n          le.fit(dataset[y].unique())\n          #label encoded data\n          data_tranformed[y] = le.transform(dataset[y])\n          #inverse label transform  data\n          data_original[y] = le.inverse_transform(data_tranformed[y])\n   return data_tranformed,data_original", "answer_comment": [], "answer_score": "1", "answer_code_list": ["def stringtocategory(dataset):\n    '''\n    @author puja.sharma\n    @see The function label encodes the object type columns and gives label      encoded and inverse tranform of the label encoded data\n    @param dataset dataframe on whoes column the label encoding has to be done\n    @return label encoded and inverse tranform of the label encoded data.\n   ''' \n   data_original = dataset[:]\n   data_tranformed = dataset[:]\n   for y in dataset.columns:\n       #check the dtype of the column object type contains strings or chars\n       if (dataset[y].dtype == object):\n          print(\"The string type features are  : \" + y)\n          le = preprocessing.LabelEncoder()\n          le.fit(dataset[y].unique())\n          #label encoded data\n          data_tranformed[y] = le.transform(dataset[y])\n          #inverse label transform  data\n          data_original[y] = le.inverse_transform(data_tranformed[y])\n   return data_tranformed,data_original\n"], "is_accepted": false}, {"answer_content": "Mainly used @Alexander answer but had to make some changes - \ncols_need_mapped = ['col1', 'col2']\n\nmapper = {col: {cat: n for n, cat in enumerate(df[col].astype('category').cat.categories)} \n     for col in df[cols_need_mapped]}\n\nfor c in cols_need_mapped :\n    df[c] = df[c].map(mapper[c])\n\nThen to re-use in the future you can just save the output to a json document and when you need it you read it in and use the .map() function like I did above.", "answer_comment": [], "answer_score": "1", "answer_code_list": ["cols_need_mapped = ['col1', 'col2']\n\nmapper = {col: {cat: n for n, cat in enumerate(df[col].astype('category').cat.categories)} \n     for col in df[cols_need_mapped]}\n\nfor c in cols_need_mapped :\n    df[c] = df[c].map(mapper[c])\n"], "is_accepted": false}, {"answer_content": "import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\ntrain=pd.read_csv('.../train.csv')\n\n#X=train.loc[:,['waterpoint_type_group','status','waterpoint_type','source_class']].values\n# Create a label encoder object \ndef MultiLabelEncoder(columnlist,dataframe):\n    for i in columnlist:\n\n        labelencoder_X=LabelEncoder()\n        dataframe[i]=labelencoder_X.fit_transform(dataframe[i])\ncolumnlist=['waterpoint_type_group','status','waterpoint_type','source_class','source_type']\nMultiLabelEncoder(columnlist,train)\n\nHere i am reading a csv from location and in function i am passing the column list i want to labelencode and the dataframe I want to apply this.", "answer_comment": [], "answer_score": "1", "answer_code_list": ["import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\ntrain=pd.read_csv('.../train.csv')\n\n#X=train.loc[:,['waterpoint_type_group','status','waterpoint_type','source_class']].values\n# Create a label encoder object \ndef MultiLabelEncoder(columnlist,dataframe):\n    for i in columnlist:\n\n        labelencoder_X=LabelEncoder()\n        dataframe[i]=labelencoder_X.fit_transform(dataframe[i])\ncolumnlist=['waterpoint_type_group','status','waterpoint_type','source_class','source_type']\nMultiLabelEncoder(columnlist,train)\n"], "is_accepted": false}, {"answer_content": "If you have all the features of type object then the first answer written above works well https://stackoverflow.com/a/31939145/5840973.\nBut, Suppose when we have mixed type columns. Then we can fetch the list of features names of type object type programmatically and then Label Encode them.\n#Fetch features of type Object\nobjFeatures = dataframe.select_dtypes(include=\"object\").columns\n\n#Iterate a loop for features of type object\nfrom sklearn import preprocessing\nle = preprocessing.LabelEncoder()\n\nfor feat in objFeatures:\n    dataframe[feat] = le.fit_transform(dataframe[feat].astype(str))\n \n\ndataframe.info()", "answer_comment": [], "answer_score": "1", "answer_code_list": ["#Fetch features of type Object\nobjFeatures = dataframe.select_dtypes(include=\"object\").columns\n\n#Iterate a loop for features of type object\nfrom sklearn import preprocessing\nle = preprocessing.LabelEncoder()\n\nfor feat in objFeatures:\n    dataframe[feat] = le.fit_transform(dataframe[feat].astype(str))\n \n\ndataframe.info()\n"], "is_accepted": false}, {"answer_content": "The problem is the shape of the data (pd dataframe) you are passing to the fit function.\nYou've got to pass 1d list.", "answer_comment": [], "answer_score": "0", "answer_code_list": [], "is_accepted": false}, {"answer_content": "How about this?\ndef MultiColumnLabelEncode(choice, columns, X):\n    LabelEncoders = []\n    if choice == 'encode':\n        for i in enumerate(columns):\n            LabelEncoders.append(LabelEncoder())\n        i=0    \n        for cols in columns:\n            X[:, cols] = LabelEncoders[i].fit_transform(X[:, cols])\n            i += 1\n    elif choice == 'decode': \n        for cols in columns:\n            X[:, cols] = LabelEncoders[i].inverse_transform(X[:, cols])\n            i += 1\n    else:\n        print('Please select correct parameter \"choice\". Available parameters: encode/decode')\n\nIt is not the most efficient, however it works and it is super simple.", "answer_comment": [], "answer_score": "0", "answer_code_list": ["def MultiColumnLabelEncode(choice, columns, X):\n    LabelEncoders = []\n    if choice == 'encode':\n        for i in enumerate(columns):\n            LabelEncoders.append(LabelEncoder())\n        i=0    \n        for cols in columns:\n            X[:, cols] = LabelEncoders[i].fit_transform(X[:, cols])\n            i += 1\n    elif choice == 'decode': \n        for cols in columns:\n            X[:, cols] = LabelEncoders[i].inverse_transform(X[:, cols])\n            i += 1\n    else:\n        print('Please select correct parameter \"choice\". Available parameters: encode/decode')\n"], "is_accepted": false}, {"answer_content": "Here is my solution to your problem. In order to convert your data-frame column containing text to encoded values just use my function text_to_numbers it returns a dictonary of LE. Key is the column name that column LabelEncoder() as a value.\ndef text_to_numbers(df):\n        le_dict = dict()\n        for i in df.columns:\n            if df[i].dtype not in [\"float64\", \"bool\", \"int64\"]:\n                le_dict[i] = preprocessing.LabelEncoder()\n                df[i] = le_dict[i].fit_transform(df[i])\n    \n        return df, le_dict\n\nThe function below will make it possible to retain an original unencoded dataframe.\n def numbers_to_text(df, le_dict):\n        for i in le_dict.keys():\n            df[i] = le_dict[i].inverse_transform(df[i])\n    \n        return df", "answer_comment": [], "answer_score": "0", "answer_code_list": ["def text_to_numbers(df):\n        le_dict = dict()\n        for i in df.columns:\n            if df[i].dtype not in [\"float64\", \"bool\", \"int64\"]:\n                le_dict[i] = preprocessing.LabelEncoder()\n                df[i] = le_dict[i].fit_transform(df[i])\n    \n        return df, le_dict\n", " def numbers_to_text(df, le_dict):\n        for i in le_dict.keys():\n            df[i] = le_dict[i].inverse_transform(df[i])\n    \n        return df\n"], "is_accepted": false}, {"answer_content": "Here is my solution to transform multiple columns in one-go, along with the accurate inverse_transformation\nfrom sklearn import preprocessing\ncolumns = ['buying','maint','lug_boot','safety','cls']  # columns names where transform is required\nfor X in columns:\n  exec(f'le_{X} = preprocessing.LabelEncoder()')  #create label encoder with name \"le_X\", where X is column name\n  exec(f'df.{X} = le_{X}.fit_transform(df.{X})')  #execute fit transform for column X with respective lable encoder \"le_X\", where X is column name\ndf.head()  # to display transformed results\n\nfor X in columns:\n  exec(f'df.{X} = le_{X}.inverse_transform(df.{X})')  #execute inverse_transform for column X with respective lable encoder \"le_X\", where X is column name\ndf.head() # to display Inverse transformed results of df", "answer_comment": [], "answer_score": "0", "answer_code_list": ["from sklearn import preprocessing\ncolumns = ['buying','maint','lug_boot','safety','cls']  # columns names where transform is required\nfor X in columns:\n  exec(f'le_{X} = preprocessing.LabelEncoder()')  #create label encoder with name \"le_X\", where X is column name\n  exec(f'df.{X} = le_{X}.fit_transform(df.{X})')  #execute fit transform for column X with respective lable encoder \"le_X\", where X is column name\ndf.head()  # to display transformed results\n\nfor X in columns:\n  exec(f'df.{X} = le_{X}.inverse_transform(df.{X})')  #execute inverse_transform for column X with respective lable encoder \"le_X\", where X is column name\ndf.head() # to display Inverse transformed results of df\n"], "is_accepted": false}], "views": "396k", "title": "Label encoding across multiple columns in scikit-learn", "question_link": "https://stackoverflow.com/questions/24458645/label-encoding-across-multiple-columns-in-scikit-learn", "question_content": "I'm trying to use scikit-learn's LabelEncoder to encode a pandas DataFrame of string labels. As the dataframe has many (50+) columns, I want to avoid creating a LabelEncoder object for each column; I'd rather just have one big LabelEncoder objects that works across all my columns of data.  \nThrowing the entire DataFrame into LabelEncoder creates the below error.  Please bear in mind that I'm using dummy data here; in actuality I'm dealing with about 50 columns of string labeled data, so need a solution that doesn't reference any columns by name. \nimport pandas\nfrom sklearn import preprocessing \n\ndf = pandas.DataFrame({\n    'pets': ['cat', 'dog', 'cat', 'monkey', 'dog', 'dog'], \n    'owner': ['Champ', 'Ron', 'Brick', 'Champ', 'Veronica', 'Ron'], \n    'location': ['San_Diego', 'New_York', 'New_York', 'San_Diego', 'San_Diego', \n                 'New_York']\n})\n\nle = preprocessing.LabelEncoder()\n\nle.fit(df)\n\n\nTraceback (most recent call last):\n        File \"\", line 1, in \n        File \"/Users/bbalin/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/label.py\", line 103, in fit\n          y = column_or_1d(y, warn=True)\n        File \"/Users/bbalin/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py\", line 306, in column_or_1d\n          raise ValueError(\"bad input shape {0}\".format(shape))\n      ValueError: bad input shape (6, 3)\n\nAny thoughts on how to get around this problem?", "question_comment": ["To simplify encoding a multi-column dataframe of string data. I'm piclking the encoding object(s), so want to avoid having to pickle/unpickle 50 separate objects. Also, I wonder if there's a way to have the encoder simplify the data, ie just returning one row with an identifier for every unique combination of variables in each column.", "There is a simple way to do this all in pandas by passing a dictionary of dictionaries to the replace method. See this answer below", "As of scikit-learn 0.20, there is no need to implement a custom class to label encode multiple columns. You can simply use OrdinalEncoder"]}]